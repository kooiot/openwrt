--- a/drivers/spi/spidev.c	2024-01-16 11:45:12.543015712 +0800
+++ b/drivers/spi/spidev.c	2024-01-16 11:41:21.473958204 +0800
@@ -724,6 +724,7 @@ static const struct of_device_id spidev_
 	{ .compatible = "semtech,sx1301", .data = &spidev_of_check },
 	{ .compatible = "silabs,em3581", .data = &spidev_of_check },
 	{ .compatible = "silabs,si3210", .data = &spidev_of_check },
+	{ .compatible = "rockchip,spidev", .data = &spidev_of_check },
 	{},
 };
 MODULE_DEVICE_TABLE(of, spidev_dt_ids);
--- a/drivers/spi/spi-rockchip.c	2022-12-22 00:36:38.000000000 +0800
+++ b/drivers/spi/spi-rockchip.c	2024-01-16 11:41:21.453958147 +0800
@@ -4,12 +4,16 @@
  * Author: Addy Ke <addy.ke@rock-chips.com>
  */
 
+#include <linux/acpi.h>
 #include <linux/clk.h>
+#include <linux/delay.h>
 #include <linux/dmaengine.h>
 #include <linux/interrupt.h>
+#include <linux/miscdevice.h>
 #include <linux/module.h>
 #include <linux/of.h>
 #include <linux/pinctrl/consumer.h>
+#include <linux/pinctrl/devinfo.h>
 #include <linux/platform_device.h>
 #include <linux/spi/spi.h>
 #include <linux/pm_runtime.h>
@@ -153,6 +157,8 @@
 
 /* sclk_out: spi master internal logic in rk3x can support 50Mhz */
 #define MAX_SCLK_OUT				50000000U
+/* max sclk of driver strength 4mA */
+#define IO_DRIVER_4MA_MAX_SCLK_OUT	24000000U
 
 /*
  * SPI_CTRLR1 is 16-bits, so we should support lengths of 0xffff + 1. However,
@@ -165,13 +171,24 @@
 #define ROCKCHIP_SPI_VER2_TYPE1			0x05EC0002
 #define ROCKCHIP_SPI_VER2_TYPE2			0x00110002
 
-#define ROCKCHIP_AUTOSUSPEND_TIMEOUT		2000
+#define ROCKCHIP_SPI_REGISTER_SIZE		0x1000
+
+enum rockchip_spi_xfer_mode {
+	ROCKCHIP_SPI_DMA,
+	ROCKCHIP_SPI_IRQ,
+	ROCKCHIP_SPI_POLL,
+};
+
+struct rockchip_spi_quirks {
+	u32 max_baud_div_in_cpha;
+};
 
 struct rockchip_spi {
 	struct device *dev;
 
 	struct clk *spiclk;
 	struct clk *apb_pclk;
+	struct clk *sclk_in;
 
 	void __iomem *regs;
 	dma_addr_t dma_addr_rx;
@@ -183,22 +200,35 @@
 	unsigned int rx_left;
 
 	atomic_t state;
+	struct completion xfer_done;
 
+	u32 version;
 	/*depth of the FIFO buffer */
 	u32 fifo_len;
 	/* frequency of spiclk */
 	u32 freq;
+	/* speed of io rate */
+	u32 speed_hz;
 
 	u8 n_bytes;
 	u8 rsd;
+	u8 csm;
+	bool poll; /* only support transfer data by cpu polling */
 
 	bool cs_asserted[ROCKCHIP_SPI_MAX_CS_NUM];
 
-	bool slave_abort;
+	struct pinctrl_state *high_speed_state;
+	bool slave_aborted;
 	bool cs_inactive; /* spi slave tansmition stop when cs inactive */
 	bool cs_high_supported; /* native CS supports active-high polarity */
+	struct gpio_desc *ready; /* spi slave transmission ready */
 
 	struct spi_transfer *xfer; /* Store xfer temporarily */
+	phys_addr_t base_addr_phy;
+	struct miscdevice miscdev;
+
+	/* quirks */
+	u32 max_baud_div_in_cpha;
 };
 
 static inline void spi_enable_chip(struct rockchip_spi *rs, bool enable)
@@ -209,15 +239,26 @@
 static inline void wait_for_tx_idle(struct rockchip_spi *rs, bool slave_mode)
 {
 	unsigned long timeout = jiffies + msecs_to_jiffies(5);
+	u32 bit_filed = SR_BUSY;
+	u32 idle_val = 0;
+	uint32_t speed, us;
+
+	if (slave_mode && rs->version == ROCKCHIP_SPI_VER2_TYPE2) {
+		bit_filed = SR_SLAVE_TX_BUSY;
+		idle_val = 0;
+	} else if (slave_mode) {
+		bit_filed = SR_TF_EMPTY;
+		idle_val = 1;
+	}
 
 	do {
-		if (slave_mode) {
-			if (!(readl_relaxed(rs->regs + ROCKCHIP_SPI_SR) & SR_SLAVE_TX_BUSY) &&
-			    !((readl_relaxed(rs->regs + ROCKCHIP_SPI_SR) & SR_BUSY)))
-				return;
-		} else {
-			if (!(readl_relaxed(rs->regs + ROCKCHIP_SPI_SR) & SR_BUSY))
-				return;
+		if ((readl_relaxed(rs->regs + ROCKCHIP_SPI_SR) & bit_filed) == idle_val) {
+			if (bit_filed == SR_TF_EMPTY) {
+				speed = rs->speed_hz;
+				us = (8 * 1000000 / speed) * 2;
+				udelay(us);
+			}
+			return;
 		}
 	} while (!time_after(jiffies, timeout));
 
@@ -226,11 +267,7 @@
 
 static u32 get_fifo_len(struct rockchip_spi *rs)
 {
-	u32 ver;
-
-	ver = readl_relaxed(rs->regs + ROCKCHIP_SPI_VERSION);
-
-	switch (ver) {
+	switch (rs->version) {
 	case ROCKCHIP_SPI_VER2_TYPE1:
 	case ROCKCHIP_SPI_VER2_TYPE2:
 		return 64;
@@ -275,19 +312,26 @@
 {
 	struct rockchip_spi *rs = spi_controller_get_devdata(ctlr);
 
+	dev_err(rs->dev, "state=%x\n", atomic_read(&rs->state));
+	dev_err(rs->dev, "tx_left=%x\n", rs->tx_left);
+	dev_err(rs->dev, "rx_left=%x\n", rs->rx_left);
+	print_hex_dump(KERN_ERR, "regs ", DUMP_PREFIX_OFFSET, 4, 4, rs->regs, 0x4c, 0);
+
 	/* stop running spi transfer
 	 * this also flushes both rx and tx fifos
 	 */
 	spi_enable_chip(rs, false);
 
-	/* make sure all interrupts are masked */
+	/* make sure all interrupts are masked and status cleared */
 	writel_relaxed(0, rs->regs + ROCKCHIP_SPI_IMR);
+	writel_relaxed(0xffffffff, rs->regs + ROCKCHIP_SPI_ICR);
 
 	if (atomic_read(&rs->state) & TXDMA)
 		dmaengine_terminate_async(ctlr->dma_tx);
 
 	if (atomic_read(&rs->state) & RXDMA)
 		dmaengine_terminate_async(ctlr->dma_rx);
+	atomic_set(&rs->state, 0);
 }
 
 static void rockchip_spi_pio_writer(struct rockchip_spi *rs)
@@ -349,7 +393,7 @@
 	struct rockchip_spi *rs = spi_controller_get_devdata(ctlr);
 
 	/* When int_cs_inactive comes, spi slave abort */
-	if (rs->cs_inactive && readl_relaxed(rs->regs + ROCKCHIP_SPI_IMR) & INT_CS_INACTIVE) {
+	if (rs->cs_inactive && readl_relaxed(rs->regs + ROCKCHIP_SPI_ISR) & INT_CS_INACTIVE) {
 		ctlr->slave_abort(ctlr);
 		writel_relaxed(0, rs->regs + ROCKCHIP_SPI_IMR);
 		writel_relaxed(0xffffffff, rs->regs + ROCKCHIP_SPI_ICR);
@@ -365,7 +409,7 @@
 		spi_enable_chip(rs, false);
 		writel_relaxed(0, rs->regs + ROCKCHIP_SPI_IMR);
 		writel_relaxed(0xffffffff, rs->regs + ROCKCHIP_SPI_ICR);
-		spi_finalize_current_transfer(ctlr);
+		complete(&rs->xfer_done);
 	}
 
 	return IRQ_HANDLED;
@@ -375,20 +419,21 @@
 				    struct spi_controller *ctlr,
 				    struct spi_transfer *xfer)
 {
-	rs->tx = xfer->tx_buf;
-	rs->rx = xfer->rx_buf;
 	rs->tx_left = rs->tx ? xfer->len / rs->n_bytes : 0;
 	rs->rx_left = xfer->len / rs->n_bytes;
 
-	if (rs->cs_inactive)
-		writel_relaxed(INT_RF_FULL | INT_CS_INACTIVE, rs->regs + ROCKCHIP_SPI_IMR);
-	else
-		writel_relaxed(INT_RF_FULL, rs->regs + ROCKCHIP_SPI_IMR);
+	writel_relaxed(0xffffffff, rs->regs + ROCKCHIP_SPI_ICR);
+
 	spi_enable_chip(rs, true);
 
 	if (rs->tx_left)
 		rockchip_spi_pio_writer(rs);
 
+	if (rs->cs_inactive)
+		writel_relaxed(INT_RF_FULL | INT_CS_INACTIVE, rs->regs + ROCKCHIP_SPI_IMR);
+	else
+		writel_relaxed(INT_RF_FULL, rs->regs + ROCKCHIP_SPI_IMR);
+
 	/* 1 means the transfer is in progress */
 	return 1;
 }
@@ -399,14 +444,16 @@
 	struct rockchip_spi *rs = spi_controller_get_devdata(ctlr);
 	int state = atomic_fetch_andnot(RXDMA, &rs->state);
 
-	if (state & TXDMA && !rs->slave_abort)
+	if (state & TXDMA && !rs->slave_aborted)
 		return;
 
 	if (rs->cs_inactive)
 		writel_relaxed(0, rs->regs + ROCKCHIP_SPI_IMR);
 
 	spi_enable_chip(rs, false);
-	spi_finalize_current_transfer(ctlr);
+	writel_relaxed(0, rs->regs + ROCKCHIP_SPI_IMR);
+	writel_relaxed(0xffffffff, rs->regs + ROCKCHIP_SPI_ICR);
+	complete(&rs->xfer_done);
 }
 
 static void rockchip_spi_dma_txcb(void *data)
@@ -415,14 +462,16 @@
 	struct rockchip_spi *rs = spi_controller_get_devdata(ctlr);
 	int state = atomic_fetch_andnot(TXDMA, &rs->state);
 
-	if (state & RXDMA && !rs->slave_abort)
+	if (state & RXDMA && !rs->slave_aborted)
 		return;
 
 	/* Wait until the FIFO data completely. */
 	wait_for_tx_idle(rs, ctlr->slave);
 
 	spi_enable_chip(rs, false);
-	spi_finalize_current_transfer(ctlr);
+	writel_relaxed(0, rs->regs + ROCKCHIP_SPI_IMR);
+	writel_relaxed(0xffffffff, rs->regs + ROCKCHIP_SPI_ICR);
+	complete(&rs->xfer_done);
 }
 
 static u32 rockchip_spi_calc_burst_size(u32 data_len)
@@ -445,9 +494,6 @@
 
 	atomic_set(&rs->state, 0);
 
-	rs->tx = xfer->tx_buf;
-	rs->rx = xfer->rx_buf;
-
 	rxdesc = NULL;
 	if (xfer->rx_buf) {
 		struct dma_slave_config rxconf = {
@@ -517,9 +563,59 @@
 	return 1;
 }
 
+static int rockchip_spi_pio_transfer(struct rockchip_spi *rs,
+		struct spi_controller *ctlr, struct spi_transfer *xfer)
+{
+	unsigned long time, timeout;
+	u32 speed_hz = xfer->speed_hz;
+	unsigned long long ms;
+	int ret = 0;
+
+	if (!speed_hz)
+		speed_hz = 100000;
+
+	ms = 8LL * 1000LL * xfer->len;
+	do_div(ms, speed_hz);
+	ms += ms + 200; /* some tolerance */
+
+	if (ms > UINT_MAX || ctlr->slave)
+		ms = UINT_MAX;
+
+	timeout = jiffies + msecs_to_jiffies(ms);
+	time = jiffies;
+	rs->tx_left = rs->tx ? xfer->len / rs->n_bytes : 0;
+	rs->rx_left = rs->rx ? xfer->len / rs->n_bytes : 0;
+
+	spi_enable_chip(rs, true);
+
+	while (rs->tx_left || rs->rx_left) {
+		if (rs->tx)
+			rockchip_spi_pio_writer(rs);
+
+		if (rs->rx)
+			rockchip_spi_pio_reader(rs);
+
+		cpu_relax();
+
+		if (time_after(time, timeout)) {
+			ret = -EIO;
+			goto out;
+		}
+	};
+
+	/* If tx, wait until the FIFO data completely. */
+	if (rs->tx)
+		wait_for_tx_idle(rs, ctlr->slave);
+
+out:
+	spi_enable_chip(rs, false);
+
+	return ret;
+}
+
 static int rockchip_spi_config(struct rockchip_spi *rs,
 		struct spi_device *spi, struct spi_transfer *xfer,
-		bool use_dma, bool slave_mode)
+		enum rockchip_spi_xfer_mode xfer_mode, bool slave_mode)
 {
 	u32 cr0 = CR0_FRF_SPI  << CR0_FRF_OFFSET
 		| CR0_BHT_8BIT << CR0_BHT_OFFSET
@@ -530,21 +626,33 @@
 
 	if (slave_mode)
 		cr0 |= CR0_OPM_SLAVE << CR0_OPM_OFFSET;
-	rs->slave_abort = false;
+	rs->slave_aborted = false;
 
 	cr0 |= rs->rsd << CR0_RSD_OFFSET;
+	cr0 |= rs->csm << CR0_CSM_OFFSET;
 	cr0 |= (spi->mode & 0x3U) << CR0_SCPH_OFFSET;
 	if (spi->mode & SPI_LSB_FIRST)
 		cr0 |= CR0_FBM_LSB << CR0_FBM_OFFSET;
 	if (spi->mode & SPI_CS_HIGH)
 		cr0 |= BIT(spi->chip_select) << CR0_SOI_OFFSET;
 
-	if (xfer->rx_buf && xfer->tx_buf)
+	if (xfer->rx_buf && xfer->tx_buf) {
 		cr0 |= CR0_XFM_TR << CR0_XFM_OFFSET;
-	else if (xfer->rx_buf)
+	} else if (xfer->rx_buf) {
 		cr0 |= CR0_XFM_RO << CR0_XFM_OFFSET;
-	else if (use_dma)
-		cr0 |= CR0_XFM_TO << CR0_XFM_OFFSET;
+	} else if (xfer->tx_buf) {
+		/*
+		 * Use the water line of rx fifo in full duplex mode to trigger
+		 * the interruption of tx irq transmission completion.
+		 */
+		if (xfer_mode == ROCKCHIP_SPI_IRQ)
+			cr0 |= CR0_XFM_TR << CR0_XFM_OFFSET;
+		else
+			cr0 |= CR0_XFM_TO << CR0_XFM_OFFSET;
+	} else {
+		dev_err(rs->dev, "no transmission buffer\n");
+		return -EINVAL;
+	}
 
 	switch (xfer->bits_per_word) {
 	case 4:
@@ -569,13 +677,26 @@
 		return -EINVAL;
 	}
 
-	if (use_dma) {
+	if (xfer_mode == ROCKCHIP_SPI_DMA) {
 		if (xfer->tx_buf)
 			dmacr |= TF_DMA_EN;
 		if (xfer->rx_buf)
 			dmacr |= RF_DMA_EN;
 	}
 
+	/*
+	 * If speed is larger than IO_DRIVER_4MA_MAX_SCLK_OUT,
+	 * set higher driver strength.
+	 */
+	if (rs->high_speed_state) {
+		if (rs->freq > IO_DRIVER_4MA_MAX_SCLK_OUT)
+			pinctrl_select_state(rs->dev->pins->p,
+					     rs->high_speed_state);
+		else
+			pinctrl_select_state(rs->dev->pins->p,
+					     rs->dev->pins->default_state);
+	}
+
 	writel_relaxed(cr0, rs->regs + ROCKCHIP_SPI_CTRLR0);
 	writel_relaxed(cr1, rs->regs + ROCKCHIP_SPI_CTRLR1);
 
@@ -593,12 +714,26 @@
 		       rs->regs + ROCKCHIP_SPI_DMARDLR);
 	writel_relaxed(dmacr, rs->regs + ROCKCHIP_SPI_DMACR);
 
+	if (rs->max_baud_div_in_cpha && xfer->speed_hz != rs->speed_hz) {
+		/* the minimum divisor is 2 */
+		if (rs->freq < 2 * xfer->speed_hz) {
+			clk_set_rate(rs->spiclk, 2 * xfer->speed_hz);
+			rs->freq = clk_get_rate(rs->spiclk);
+		}
+
+		if ((spi->mode & SPI_CPHA) && (DIV_ROUND_UP(rs->freq, xfer->speed_hz) > rs->max_baud_div_in_cpha)) {
+			clk_set_rate(rs->spiclk, rs->max_baud_div_in_cpha * xfer->speed_hz);
+			rs->freq = clk_get_rate(rs->spiclk);
+		}
+	}
+
 	/* the hardware only supports an even clock divisor, so
 	 * round divisor = spiclk / speed up to nearest even number
 	 * so that the resulting speed is <= the requested speed
 	 */
 	writel_relaxed(2 * DIV_ROUND_UP(rs->freq, 2 * xfer->speed_hz),
 			rs->regs + ROCKCHIP_SPI_BAUDR);
+	rs->speed_hz = xfer->speed_hz;
 
 	return 0;
 }
@@ -612,49 +747,54 @@
 {
 	struct rockchip_spi *rs = spi_controller_get_devdata(ctlr);
 	u32 rx_fifo_left;
-	struct dma_tx_state state;
-	enum dma_status status;
 
-	/* Get current dma rx point */
-	if (atomic_read(&rs->state) & RXDMA) {
-		dmaengine_pause(ctlr->dma_rx);
-		status = dmaengine_tx_status(ctlr->dma_rx, ctlr->dma_rx->cookie, &state);
-		if (status == DMA_ERROR) {
-			rs->rx = rs->xfer->rx_buf;
-			rs->xfer->len = 0;
-			rx_fifo_left = readl_relaxed(rs->regs + ROCKCHIP_SPI_RXFLR);
-			for (; rx_fifo_left; rx_fifo_left--)
-				readl_relaxed(rs->regs + ROCKCHIP_SPI_RXDR);
-			goto out;
-		} else {
-			rs->rx += rs->xfer->len - rs->n_bytes * state.residue;
+	/* Flush rx fifo */
+	rx_fifo_left = readl_relaxed(rs->regs + ROCKCHIP_SPI_RXFLR);
+	for (; rx_fifo_left; rx_fifo_left--)
+		readl_relaxed(rs->regs + ROCKCHIP_SPI_RXDR);
+
+	rs->slave_aborted = true;
+	complete(&rs->xfer_done);
+
+	return 0;
+}
+
+static int rockchip_spi_transfer_wait(struct spi_controller *ctlr,
+				      struct spi_transfer *xfer)
+{
+	struct rockchip_spi *rs = spi_controller_get_devdata(ctlr);
+	u32 speed_hz = xfer->speed_hz;
+	unsigned long long ms;
+
+	if (spi_controller_is_slave(ctlr)) {
+		if (wait_for_completion_interruptible(&rs->xfer_done)) {
+			dev_dbg(rs->dev, "RK SPI transfer interrupted\n");
+			return -EINTR;
 		}
-	}
 
-	/* Get the valid data left in rx fifo and set rs->xfer->len real rx size */
-	if (rs->rx) {
-		rx_fifo_left = readl_relaxed(rs->regs + ROCKCHIP_SPI_RXFLR);
-		for (; rx_fifo_left; rx_fifo_left--) {
-			u32 rxw = readl_relaxed(rs->regs + ROCKCHIP_SPI_RXDR);
-
-			if (rs->n_bytes == 1)
-				*(u8 *)rs->rx = (u8)rxw;
-			else
-				*(u16 *)rs->rx = (u16)rxw;
-			rs->rx += rs->n_bytes;
+		if (rs->slave_aborted) {
+			dev_err(rs->dev, "RK SPI transfer slave abort\n");
+			return -EIO;
 		}
-		rs->xfer->len = (unsigned int)(rs->rx - rs->xfer->rx_buf);
-	}
+	} else {
+		if (!speed_hz)
+			speed_hz = 100000;
 
-out:
-	if (atomic_read(&rs->state) & RXDMA)
-		dmaengine_terminate_sync(ctlr->dma_rx);
-	if (atomic_read(&rs->state) & TXDMA)
-		dmaengine_terminate_sync(ctlr->dma_tx);
-	atomic_set(&rs->state, 0);
-	spi_enable_chip(rs, false);
-	rs->slave_abort = true;
-	spi_finalize_current_transfer(ctlr);
+		ms = 8LL * 1000LL * xfer->len;
+		do_div(ms, speed_hz);
+		ms += ms + 200; /* some tolerance */
+
+		if (ms > UINT_MAX)
+			ms = UINT_MAX;
+
+		ms = wait_for_completion_timeout(&rs->xfer_done,
+						 msecs_to_jiffies(ms));
+
+		if (ms == 0) {
+			dev_err(rs->dev, "RK SPI transfer timed out\n");
+			return -ETIMEDOUT;
+		}
+	}
 
 	return 0;
 }
@@ -667,10 +807,11 @@
 	struct rockchip_spi *rs = spi_controller_get_devdata(ctlr);
 	int ret;
 	bool use_dma;
+	enum rockchip_spi_xfer_mode xfer_mode;
 
 	/* Zero length transfers won't trigger an interrupt on completion */
 	if (!xfer->len) {
-		spi_finalize_current_transfer(ctlr);
+		complete(&rs->xfer_done);
 		return 1;
 	}
 
@@ -689,16 +830,49 @@
 
 	rs->n_bytes = xfer->bits_per_word <= 8 ? 1 : 2;
 	rs->xfer = xfer;
-	use_dma = ctlr->can_dma ? ctlr->can_dma(ctlr, spi, xfer) : false;
+	if (rs->poll) {
+		xfer_mode = ROCKCHIP_SPI_POLL;
+	} else {
+		use_dma = ctlr->can_dma ? ctlr->can_dma(ctlr, spi, xfer) : false;
+		if (use_dma)
+			xfer_mode = ROCKCHIP_SPI_DMA;
+		else
+			xfer_mode = ROCKCHIP_SPI_IRQ;
+	}
 
-	ret = rockchip_spi_config(rs, spi, xfer, use_dma, ctlr->slave);
+	ret = rockchip_spi_config(rs, spi, xfer, xfer_mode, ctlr->slave);
 	if (ret)
 		return ret;
 
-	if (use_dma)
-		return rockchip_spi_prepare_dma(rs, ctlr, xfer);
+	rs->tx = xfer->tx_buf;
+	rs->rx = xfer->rx_buf;
+
+	reinit_completion(&rs->xfer_done);
+
+	switch (xfer_mode) {
+	case ROCKCHIP_SPI_POLL:
+		ret = rockchip_spi_pio_transfer(rs, ctlr, xfer);
+		break;
+	case ROCKCHIP_SPI_DMA:
+		ret = rockchip_spi_prepare_dma(rs, ctlr, xfer);
+		break;
+	default:
+		ret = rockchip_spi_prepare_irq(rs, ctlr, xfer);
+	}
+
+	if (rs->ready) {
+		gpiod_set_value(rs->ready, 0);
+		udelay(1);
+		gpiod_set_value(rs->ready, 1);
+	}
+
+	if (ret > 0)
+		ret = rockchip_spi_transfer_wait(ctlr, xfer);
+
+	if (rs->ready)
+		gpiod_set_value(rs->ready, 0);
 
-	return rockchip_spi_prepare_irq(rs, ctlr, xfer);
+	return ret;
 }
 
 static bool rockchip_spi_can_dma(struct spi_controller *ctlr,
@@ -729,12 +903,9 @@
 
 	cr0 = readl_relaxed(rs->regs + ROCKCHIP_SPI_CTRLR0);
 
-	cr0 &= ~(0x3 << CR0_SCPH_OFFSET);
 	cr0 |= ((spi->mode & 0x3) << CR0_SCPH_OFFSET);
-	if (spi->mode & SPI_CS_HIGH && spi->chip_select <= 1)
+	if (spi->mode & SPI_CS_HIGH)
 		cr0 |= BIT(spi->chip_select) << CR0_SOI_OFFSET;
-	else if (spi->chip_select <= 1)
-		cr0 &= ~(BIT(spi->chip_select) << CR0_SOI_OFFSET);
 
 	writel_relaxed(cr0, rs->regs + ROCKCHIP_SPI_CTRLR0);
 
@@ -743,6 +914,60 @@
 	return 0;
 }
 
+static int rockchip_spi_misc_open(struct inode *inode, struct file *filp)
+{
+	struct miscdevice *misc = filp->private_data;
+	struct spi_controller *ctlr = dev_get_drvdata(misc->parent);
+	struct rockchip_spi *rs = spi_controller_get_devdata(ctlr);
+
+	pm_runtime_get_sync(rs->dev);
+
+	return 0;
+}
+
+static int rockchip_spi_misc_release(struct inode *inode, struct file *filp)
+{
+	struct miscdevice *misc = filp->private_data;
+	struct spi_controller *ctlr = dev_get_drvdata(misc->parent);
+	struct rockchip_spi *rs = spi_controller_get_devdata(ctlr);
+
+	pm_runtime_put(rs->dev);
+
+	return 0;
+}
+
+static int rockchip_spi_mmap(struct file *filp, struct vm_area_struct *vma)
+{
+	struct miscdevice *misc = filp->private_data;
+	struct spi_controller *ctlr = dev_get_drvdata(misc->parent);
+	struct rockchip_spi *rs = spi_controller_get_devdata(ctlr);
+	size_t size = vma->vm_end - vma->vm_start;
+	int err;
+
+	if (size > ROCKCHIP_SPI_REGISTER_SIZE) {
+		dev_warn(misc->parent, "mmap size is out of limitation\n");
+		return -EINVAL;
+	}
+
+	vma->vm_flags |= VM_IO;
+	vma->vm_flags |= (VM_DONTEXPAND | VM_DONTDUMP);
+	vma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);
+
+	err = remap_pfn_range(vma, vma->vm_start,
+			      __phys_to_pfn(rs->base_addr_phy),
+			      size, vma->vm_page_prot);
+	if (err)
+		return -EAGAIN;
+
+	return 0;
+}
+
+static const struct file_operations rockchip_spi_misc_fops = {
+	.open		= rockchip_spi_misc_open,
+	.release	= rockchip_spi_misc_release,
+	.mmap		= rockchip_spi_mmap,
+};
+
 static int rockchip_spi_probe(struct platform_device *pdev)
 {
 	int ret;
@@ -750,8 +975,11 @@
 	struct spi_controller *ctlr;
 	struct resource *mem;
 	struct device_node *np = pdev->dev.of_node;
-	u32 rsd_nsecs, num_cs;
+	u32 rsd_nsecs, num_cs, csm;
 	bool slave_mode;
+	struct pinctrl *pinctrl = NULL;
+	const struct rockchip_spi_quirks *quirks_cfg;
+	u32 val;
 
 	slave_mode = of_property_read_bool(np, "spi-slave");
 
@@ -765,6 +993,7 @@
 	if (!ctlr)
 		return -ENOMEM;
 
+	ctlr->rt = device_property_read_bool(&pdev->dev, "rockchip,rt");
 	platform_set_drvdata(pdev, ctlr);
 
 	rs = spi_controller_get_devdata(ctlr);
@@ -777,21 +1006,31 @@
 		ret =  PTR_ERR(rs->regs);
 		goto err_put_ctlr;
 	}
+	rs->base_addr_phy = mem->start;
 
-	rs->apb_pclk = devm_clk_get(&pdev->dev, "apb_pclk");
+	if (!has_acpi_companion(&pdev->dev))
+		rs->apb_pclk = devm_clk_get(&pdev->dev, "apb_pclk");
 	if (IS_ERR(rs->apb_pclk)) {
 		dev_err(&pdev->dev, "Failed to get apb_pclk\n");
 		ret = PTR_ERR(rs->apb_pclk);
 		goto err_put_ctlr;
 	}
 
-	rs->spiclk = devm_clk_get(&pdev->dev, "spiclk");
+	if (!has_acpi_companion(&pdev->dev))
+		rs->spiclk = devm_clk_get(&pdev->dev, "spiclk");
 	if (IS_ERR(rs->spiclk)) {
 		dev_err(&pdev->dev, "Failed to get spi_pclk\n");
 		ret = PTR_ERR(rs->spiclk);
 		goto err_put_ctlr;
 	}
 
+	rs->sclk_in = devm_clk_get_optional(&pdev->dev, "sclk_in");
+	if (IS_ERR(rs->sclk_in)) {
+		dev_err(&pdev->dev, "Failed to get sclk_in\n");
+		ret = PTR_ERR(rs->sclk_in);
+		goto err_put_ctlr;
+	}
+
 	ret = clk_prepare_enable(rs->apb_pclk);
 	if (ret < 0) {
 		dev_err(&pdev->dev, "Failed to enable apb_pclk\n");
@@ -804,22 +1043,35 @@
 		goto err_disable_apbclk;
 	}
 
+	ret = clk_prepare_enable(rs->sclk_in);
+	if (ret < 0) {
+		dev_err(&pdev->dev, "Failed to enable sclk_in\n");
+		goto err_disable_spiclk;
+	}
+
 	spi_enable_chip(rs, false);
 
 	ret = platform_get_irq(pdev, 0);
 	if (ret < 0)
-		goto err_disable_spiclk;
+		goto err_disable_sclk_in;
 
 	ret = devm_request_threaded_irq(&pdev->dev, ret, rockchip_spi_isr, NULL,
 			IRQF_ONESHOT, dev_name(&pdev->dev), ctlr);
 	if (ret)
-		goto err_disable_spiclk;
+		goto err_disable_sclk_in;
 
 	rs->dev = &pdev->dev;
+
 	rs->freq = clk_get_rate(rs->spiclk);
+	if (!rs->freq) {
+		ret = device_property_read_u32(&pdev->dev, "clock-frequency", &rs->freq);
+		if (ret) {
+			dev_warn(rs->dev, "Failed to get clock or clock-frequency property\n");
+			goto err_disable_sclk_in;
+		}
+	}
 
-	if (!of_property_read_u32(pdev->dev.of_node, "rx-sample-delay-ns",
-				  &rsd_nsecs)) {
+	if (!device_property_read_u32(&pdev->dev, "rx-sample-delay-ns", &rsd_nsecs)) {
 		/* rx sample delay is expressed in parent clock cycles (max 3) */
 		u32 rsd = DIV_ROUND_CLOSEST(rsd_nsecs * (rs->freq >> 8),
 				1000000000 >> 8);
@@ -835,15 +1087,33 @@
 		rs->rsd = rsd;
 	}
 
+	if (!device_property_read_u32(&pdev->dev, "csm", &csm)) {
+		if (csm > CR0_CSM_ONE)	{
+			dev_warn(rs->dev, "The csm value %u exceeds the limit, clamping at %u\n",
+				 csm, CR0_CSM_ONE);
+			csm = CR0_CSM_ONE;
+		}
+		rs->csm = csm;
+	}
+
+	rs->version = readl_relaxed(rs->regs + ROCKCHIP_SPI_VERSION);
 	rs->fifo_len = get_fifo_len(rs);
 	if (!rs->fifo_len) {
 		dev_err(&pdev->dev, "Failed to get fifo length\n");
 		ret = -EINVAL;
-		goto err_disable_spiclk;
+		goto err_disable_sclk_in;
+	}
+	quirks_cfg = device_get_match_data(&pdev->dev);
+	if (quirks_cfg)
+		rs->max_baud_div_in_cpha = quirks_cfg->max_baud_div_in_cpha;
+
+	if (!device_property_read_u32(&pdev->dev, "rockchip,autosuspend-delay-ms", &val)) {
+		if (val > 0) {
+			pm_runtime_set_autosuspend_delay(&pdev->dev, val);
+			pm_runtime_use_autosuspend(&pdev->dev);
+		}
 	}
 
-	pm_runtime_set_autosuspend_delay(&pdev->dev, ROCKCHIP_AUTOSUSPEND_TIMEOUT);
-	pm_runtime_use_autosuspend(&pdev->dev);
 	pm_runtime_set_active(&pdev->dev);
 	pm_runtime_enable(&pdev->dev);
 
@@ -860,7 +1130,7 @@
 		 * rk spi0 has two native cs, spi1..5 one cs only
 		 * if num-cs is missing in the dts, default to 1
 		 */
-		if (of_property_read_u32(np, "num-cs", &num_cs))
+		if (device_property_read_u32(&pdev->dev, "num-cs", &num_cs))
 			num_cs = 1;
 		ctlr->num_chipselect = num_cs;
 		ctlr->use_gpio_descriptors = true;
@@ -903,11 +1173,19 @@
 		ctlr->can_dma = rockchip_spi_can_dma;
 	}
 
-	switch (readl_relaxed(rs->regs + ROCKCHIP_SPI_VERSION)) {
+	rs->poll = device_property_read_bool(&pdev->dev, "rockchip,poll-only");
+	init_completion(&rs->xfer_done);
+	if (rs->poll && slave_mode) {
+		dev_err(rs->dev, "only support rockchip,poll-only property in master mode\n");
+		ret = -EINVAL;
+		goto err_free_dma_rx;
+	}
+
+	switch (rs->version) {
 	case ROCKCHIP_SPI_VER2_TYPE2:
 		rs->cs_high_supported = true;
 		ctlr->mode_bits |= SPI_CS_HIGH;
-		if (ctlr->can_dma && slave_mode)
+		if (slave_mode)
 			rs->cs_inactive = true;
 		else
 			rs->cs_inactive = false;
@@ -916,6 +1194,24 @@
 		rs->cs_inactive = false;
 		break;
 	}
+	if (device_property_read_bool(&pdev->dev, "rockchip,cs-inactive-disable"))
+		rs->cs_inactive = false;
+
+	pinctrl = devm_pinctrl_get(&pdev->dev);
+	if (!IS_ERR(pinctrl)) {
+		rs->high_speed_state = pinctrl_lookup_state(pinctrl, "high_speed");
+		if (IS_ERR_OR_NULL(rs->high_speed_state)) {
+			dev_warn(&pdev->dev, "no high_speed pinctrl state\n");
+			rs->high_speed_state = NULL;
+		}
+	}
+
+	rs->ready = devm_gpiod_get_optional(&pdev->dev, "ready", GPIOD_OUT_HIGH);
+	if (IS_ERR(rs->ready)) {
+		ret = dev_err_probe(&pdev->dev, PTR_ERR(rs->ready),
+				    "invalid ready-gpios property in node\n");
+		goto err_free_dma_rx;
+	}
 
 	ret = devm_spi_register_controller(&pdev->dev, ctlr);
 	if (ret < 0) {
@@ -923,6 +1219,25 @@
 		goto err_free_dma_rx;
 	}
 
+	if (IS_ENABLED(CONFIG_SPI_ROCKCHIP_MISCDEV)) {
+		char misc_name[20];
+
+		snprintf(misc_name, sizeof(misc_name), "rkspi-dev%d", ctlr->bus_num);
+		rs->miscdev.minor = MISC_DYNAMIC_MINOR;
+		rs->miscdev.name = misc_name;
+		rs->miscdev.fops = &rockchip_spi_misc_fops;
+		rs->miscdev.parent = &pdev->dev;
+
+		ret = misc_register(&rs->miscdev);
+		if (ret)
+			dev_err(&pdev->dev, "failed to register misc device %s\n", misc_name);
+		else
+			dev_info(&pdev->dev, "register misc device %s\n", misc_name);
+	}
+
+	dev_info(rs->dev, "probed, poll=%d, rsd=%d, cs-inactive=%d, ready=%d\n",
+		 rs->poll, rs->rsd, rs->cs_inactive, rs->ready ? 1 : 0);
+
 	return 0;
 
 err_free_dma_rx:
@@ -933,6 +1248,8 @@
 		dma_release_channel(ctlr->dma_tx);
 err_disable_pm_runtime:
 	pm_runtime_disable(&pdev->dev);
+err_disable_sclk_in:
+	clk_disable_unprepare(rs->sclk_in);
 err_disable_spiclk:
 	clk_disable_unprepare(rs->spiclk);
 err_disable_apbclk:
@@ -948,8 +1265,12 @@
 	struct spi_controller *ctlr = spi_controller_get(platform_get_drvdata(pdev));
 	struct rockchip_spi *rs = spi_controller_get_devdata(ctlr);
 
+	if (IS_ENABLED(CONFIG_SPI_ROCKCHIP_MISCDEV))
+		misc_deregister(&rs->miscdev);
+
 	pm_runtime_get_sync(&pdev->dev);
 
+	clk_disable_unprepare(rs->sclk_in);
 	clk_disable_unprepare(rs->spiclk);
 	clk_disable_unprepare(rs->apb_pclk);
 
@@ -967,85 +1288,91 @@
 	return 0;
 }
 
-#ifdef CONFIG_PM_SLEEP
-static int rockchip_spi_suspend(struct device *dev)
+#ifdef CONFIG_PM
+static int rockchip_spi_runtime_suspend(struct device *dev)
 {
-	int ret;
 	struct spi_controller *ctlr = dev_get_drvdata(dev);
+	struct rockchip_spi *rs = spi_controller_get_devdata(ctlr);
 
-	ret = spi_controller_suspend(ctlr);
-	if (ret < 0)
-		return ret;
-
-	ret = pm_runtime_force_suspend(dev);
-	if (ret < 0)
-		return ret;
-
-	pinctrl_pm_select_sleep_state(dev);
+	clk_disable_unprepare(rs->spiclk);
+	clk_disable_unprepare(rs->apb_pclk);
 
 	return 0;
 }
 
-static int rockchip_spi_resume(struct device *dev)
+static int rockchip_spi_runtime_resume(struct device *dev)
 {
 	int ret;
 	struct spi_controller *ctlr = dev_get_drvdata(dev);
 	struct rockchip_spi *rs = spi_controller_get_devdata(ctlr);
 
-	pinctrl_pm_select_default_state(dev);
-
-	ret = pm_runtime_force_resume(dev);
+	ret = clk_prepare_enable(rs->apb_pclk);
 	if (ret < 0)
 		return ret;
 
-	ret = spi_controller_resume(ctlr);
-	if (ret < 0) {
-		clk_disable_unprepare(rs->spiclk);
+	ret = clk_prepare_enable(rs->spiclk);
+	if (ret < 0)
 		clk_disable_unprepare(rs->apb_pclk);
-	}
 
 	return 0;
 }
-#endif /* CONFIG_PM_SLEEP */
+#endif /* CONFIG_PM */
 
-#ifdef CONFIG_PM
-static int rockchip_spi_runtime_suspend(struct device *dev)
+#ifdef CONFIG_PM_SLEEP
+static int rockchip_spi_suspend(struct device *dev)
 {
+	int ret;
 	struct spi_controller *ctlr = dev_get_drvdata(dev);
-	struct rockchip_spi *rs = spi_controller_get_devdata(ctlr);
 
-	clk_disable_unprepare(rs->spiclk);
-	clk_disable_unprepare(rs->apb_pclk);
+	ret = spi_controller_suspend(ctlr);
+	if (ret < 0)
+		return ret;
+
+	/* Avoid redundant clock disable */
+	if (!pm_runtime_status_suspended(dev))
+		rockchip_spi_runtime_suspend(dev);
+
+	pinctrl_pm_select_sleep_state(dev);
 
 	return 0;
 }
 
-static int rockchip_spi_runtime_resume(struct device *dev)
+static int rockchip_spi_resume(struct device *dev)
 {
 	int ret;
 	struct spi_controller *ctlr = dev_get_drvdata(dev);
-	struct rockchip_spi *rs = spi_controller_get_devdata(ctlr);
 
-	ret = clk_prepare_enable(rs->apb_pclk);
-	if (ret < 0)
-		return ret;
+	pinctrl_pm_select_default_state(dev);
 
-	ret = clk_prepare_enable(rs->spiclk);
+	if (!pm_runtime_status_suspended(dev)) {
+		ret = rockchip_spi_runtime_resume(dev);
+		if (ret < 0)
+			return ret;
+	}
+
+	ret = spi_controller_resume(ctlr);
 	if (ret < 0)
-		clk_disable_unprepare(rs->apb_pclk);
+		rockchip_spi_runtime_suspend(dev);
 
 	return 0;
 }
-#endif /* CONFIG_PM */
+#endif /* CONFIG_PM_SLEEP */
 
 static const struct dev_pm_ops rockchip_spi_pm = {
-	SET_SYSTEM_SLEEP_PM_OPS(rockchip_spi_suspend, rockchip_spi_resume)
+	SET_NOIRQ_SYSTEM_SLEEP_PM_OPS(rockchip_spi_suspend, rockchip_spi_resume)
 	SET_RUNTIME_PM_OPS(rockchip_spi_runtime_suspend,
 			   rockchip_spi_runtime_resume, NULL)
 };
 
+static const struct rockchip_spi_quirks rockchip_spi_quirks_cfg = {
+	.max_baud_div_in_cpha	= 4,
+};
+
 static const struct of_device_id rockchip_spi_dt_match[] = {
-	{ .compatible = "rockchip,px30-spi", },
+	{
+		.compatible = "rockchip,px30-spi",
+		.data = &rockchip_spi_quirks_cfg,
+	},
 	{ .compatible = "rockchip,rk3036-spi", },
 	{ .compatible = "rockchip,rk3066-spi", },
 	{ .compatible = "rockchip,rk3188-spi", },
@@ -1055,6 +1382,7 @@
 	{ .compatible = "rockchip,rk3328-spi", },
 	{ .compatible = "rockchip,rk3368-spi", },
 	{ .compatible = "rockchip,rk3399-spi", },
+	{ .compatible = "rockchip,rv1106-spi", },
 	{ .compatible = "rockchip,rv1108-spi", },
 	{ .compatible = "rockchip,rv1126-spi", },
 	{ },
--- a/drivers/spi/spi-rockchip-sfc.c	2022-12-22 00:36:38.000000000 +0800
+++ b/drivers/spi/spi-rockchip-sfc.c	2024-01-16 11:41:21.453958147 +0800
@@ -8,17 +8,20 @@
  *	   Jon Lin <Jon.lin@rock-chips.com>
  */
 
+#include <linux/acpi.h>
 #include <linux/bitops.h>
 #include <linux/clk.h>
 #include <linux/completion.h>
 #include <linux/dma-mapping.h>
 #include <linux/iopoll.h>
+#include <linux/interrupt.h>
 #include <linux/mm.h>
 #include <linux/module.h>
 #include <linux/of.h>
+#include <linux/pinctrl/consumer.h>
 #include <linux/platform_device.h>
+#include <linux/pm_runtime.h>
 #include <linux/slab.h>
-#include <linux/interrupt.h>
 #include <linux/spi/spi-mem.h>
 
 /* System control */
@@ -110,6 +113,8 @@
 #define  SFC_VER_3			0x3
 #define  SFC_VER_4			0x4
 #define  SFC_VER_5			0x5
+#define  SFC_VER_6			0x6
+#define  SFC_VER_8			0x8
 
 /* Delay line controller resiter */
 #define SFC_DLL_CTRL0			0x3C
@@ -156,10 +161,8 @@
  */
 #define SFC_MAX_CHIPSELECT_NUM		4
 
-/* The SFC can transfer max 16KB - 1 at one time
- * we set it to 15.5KB here for alignment.
- */
 #define SFC_MAX_IOSIZE_VER3		(512 * 31)
+#define SFC_MAX_IOSIZE_VER4		(0xFFFFFFFFU)
 
 /* DMA is only enabled for large data transmission */
 #define SFC_DMA_TRANS_THRETHOLD		(0x40)
@@ -168,6 +171,12 @@
  * 150MHz. No minimum or average value is suggested.
  */
 #define SFC_MAX_SPEED		(150 * 1000 * 1000)
+#define SFC_DLL_THRESHOLD_RATE	(50 * 1000 * 1000)
+
+#define SFC_DLL_TRANING_STEP		10	/* Training step */
+#define SFC_DLL_TRANING_VALID_WINDOW	80	/* Valid DLL winbow */
+
+#define ROCKCHIP_AUTOSUSPEND_DELAY	2000
 
 struct rockchip_sfc {
 	struct device *dev;
@@ -181,6 +190,7 @@
 	struct completion cp;
 	bool use_dma;
 	u32 max_iosize;
+	u32 dll_cells;
 	u16 version;
 };
 
@@ -215,6 +225,34 @@
 	return SFC_MAX_IOSIZE_VER3;
 }
 
+static u32 rockchip_sfc_get_max_dll_cells(struct rockchip_sfc *sfc)
+{
+	switch (rockchip_sfc_get_version(sfc)) {
+	case SFC_VER_8:
+	case SFC_VER_6:
+	case SFC_VER_5:
+		return SFC_DLL_CTRL0_DLL_MAX_VER5;
+	case SFC_VER_4:
+		return SFC_DLL_CTRL0_DLL_MAX_VER4;
+	default:
+		return 0;
+	}
+}
+
+static void rockchip_sfc_set_delay_lines(struct rockchip_sfc *sfc, u16 cells)
+{
+	u16 cell_max = (u16)rockchip_sfc_get_max_dll_cells(sfc);
+	u32 val = 0;
+
+	if (cells > cell_max)
+		cells = cell_max;
+
+	if (cells)
+		val = SFC_DLL_CTRL0_SCLK_SMP_DLL | cells;
+
+	writel(val, sfc->regbase + SFC_DLL_CTRL0);
+}
+
 static void rockchip_sfc_irq_unmask(struct rockchip_sfc *sfc, u32 mask)
 {
 	u32 reg;
@@ -472,6 +510,16 @@
 	int ret = 0;
 	u32 status;
 
+	/*
+	 * There is very little data left in fifo, and the controller will
+	 * complete the transmission in a short period of time.
+	 */
+	ret = readl_poll_timeout(sfc->regbase + SFC_SR, status,
+				 !(status & SFC_SR_IS_BUSY),
+				 0, 10);
+	if (!ret)
+		return 0;
+
 	ret = readl_poll_timeout(sfc->regbase + SFC_SR, status,
 				 !(status & SFC_SR_IS_BUSY),
 				 20, timeout_us);
@@ -485,17 +533,124 @@
 	return ret;
 }
 
+static int rockchip_sfc_exec_op_bypass(struct rockchip_sfc *sfc,
+				       struct spi_mem *mem,
+				       const struct spi_mem_op *op)
+{
+	u32 len = min_t(u32, op->data.nbytes, sfc->max_iosize);
+	u32 ret;
+
+	rockchip_sfc_adjust_op_work((struct spi_mem_op *)op);
+	rockchip_sfc_xfer_setup(sfc, mem, op, len);
+	ret = rockchip_sfc_xfer_data_poll(sfc, op, len);
+	if (ret != len) {
+		dev_err(sfc->dev, "xfer data failed ret %d\n", ret);
+
+		return -EIO;
+	}
+
+	return rockchip_sfc_xfer_done(sfc, 100000);
+}
+
+static void rockchip_sfc_delay_lines_tuning(struct rockchip_sfc *sfc, struct spi_mem *mem)
+{
+	struct spi_mem_op op = SPI_MEM_OP(SPI_MEM_OP_CMD(0x9F, 1),
+						SPI_MEM_OP_NO_ADDR,
+						SPI_MEM_OP_NO_DUMMY,
+						SPI_MEM_OP_DATA_IN(3, NULL, 1));
+	u8 id[3], id_temp[3];
+	u16 cell_max = (u16)rockchip_sfc_get_max_dll_cells(sfc);
+	u16 right, left = 0;
+	u16 step = SFC_DLL_TRANING_STEP;
+	bool dll_valid = false;
+
+	clk_set_rate(sfc->clk, SFC_DLL_THRESHOLD_RATE);
+	op.data.buf.in = &id;
+	rockchip_sfc_exec_op_bypass(sfc, mem, &op);
+	if ((0xFF == id[0] && 0xFF == id[1]) ||
+	    (0x00 == id[0] && 0x00 == id[1])) {
+		dev_dbg(sfc->dev, "no dev, dll by pass\n");
+		clk_set_rate(sfc->clk, mem->spi->max_speed_hz);
+
+		return;
+	}
+
+	clk_set_rate(sfc->clk, mem->spi->max_speed_hz);
+	op.data.buf.in = &id_temp;
+	for (right = 0; right <= cell_max; right += step) {
+		int ret;
+
+		rockchip_sfc_set_delay_lines(sfc, right);
+		rockchip_sfc_exec_op_bypass(sfc, mem, &op);
+		dev_dbg(sfc->dev, "dll read flash id:%x %x %x\n",
+			id_temp[0], id_temp[1], id_temp[2]);
+
+		ret = memcmp(&id, &id_temp, 3);
+		if (dll_valid && ret) {
+			right -= step;
+
+			break;
+		}
+		if (!dll_valid && !ret)
+			left = right;
+
+		if (!ret)
+			dll_valid = true;
+
+		/* Add cell_max to loop */
+		if (right == cell_max)
+			break;
+		if (right + step > cell_max)
+			right = cell_max - step;
+	}
+
+	if (dll_valid && (right - left) >= SFC_DLL_TRANING_VALID_WINDOW) {
+		if (left == 0 && right < cell_max)
+			sfc->dll_cells = left + (right - left) * 2 / 5;
+		else
+			sfc->dll_cells = left + (right - left) / 2;
+	} else {
+		sfc->dll_cells = 0;
+	}
+
+	if (sfc->dll_cells) {
+		dev_dbg(sfc->dev, "%d %d %d dll training success in %dMHz max_cells=%u sfc_ver=%d\n",
+			left, right, sfc->dll_cells, mem->spi->max_speed_hz,
+			rockchip_sfc_get_max_dll_cells(sfc), rockchip_sfc_get_version(sfc));
+		rockchip_sfc_set_delay_lines(sfc, (u16)sfc->dll_cells);
+	} else {
+		dev_err(sfc->dev, "%d %d dll training failed in %dMHz, reduce the frequency\n",
+			left, right, mem->spi->max_speed_hz);
+		rockchip_sfc_set_delay_lines(sfc, 0);
+		clk_set_rate(sfc->clk, SFC_DLL_THRESHOLD_RATE);
+		mem->spi->max_speed_hz = clk_get_rate(sfc->clk);
+	}
+}
+
 static int rockchip_sfc_exec_mem_op(struct spi_mem *mem, const struct spi_mem_op *op)
 {
 	struct rockchip_sfc *sfc = spi_master_get_devdata(mem->spi->master);
 	u32 len = op->data.nbytes;
 	int ret;
 
-	if (unlikely(mem->spi->max_speed_hz != sfc->frequency)) {
+	ret = pm_runtime_get_sync(sfc->dev);
+	if (ret < 0) {
+		pm_runtime_put_noidle(sfc->dev);
+		return ret;
+	}
+
+	if (unlikely(mem->spi->max_speed_hz != sfc->frequency) && !has_acpi_companion(sfc->dev)) {
 		ret = clk_set_rate(sfc->clk, mem->spi->max_speed_hz);
 		if (ret)
-			return ret;
+			goto out;
 		sfc->frequency = mem->spi->max_speed_hz;
+		if (rockchip_sfc_get_version(sfc) >= SFC_VER_4) {
+			if (clk_get_rate(sfc->clk) > SFC_DLL_THRESHOLD_RATE)
+				rockchip_sfc_delay_lines_tuning(sfc, mem);
+			else
+				rockchip_sfc_set_delay_lines(sfc, 0);
+		}
+
 		dev_dbg(sfc->dev, "set_freq=%dHz real_freq=%ldHz\n",
 			sfc->frequency, clk_get_rate(sfc->clk));
 	}
@@ -503,7 +658,7 @@
 	rockchip_sfc_adjust_op_work((struct spi_mem_op *)op);
 	rockchip_sfc_xfer_setup(sfc, mem, op, len);
 	if (len) {
-		if (likely(sfc->use_dma) && len >= SFC_DMA_TRANS_THRETHOLD) {
+		if (likely(sfc->use_dma) && len >= SFC_DMA_TRANS_THRETHOLD && !(len & 0x3)) {
 			init_completion(&sfc->cp);
 			rockchip_sfc_irq_unmask(sfc, SFC_IMR_DMA);
 			ret = rockchip_sfc_xfer_data_dma(sfc, op, len);
@@ -514,11 +669,17 @@
 		if (ret != len) {
 			dev_err(sfc->dev, "xfer data failed ret %d dir %d\n", ret, op->data.dir);
 
-			return -EIO;
+			ret = -EIO;
+			goto out;
 		}
 	}
 
-	return rockchip_sfc_xfer_done(sfc, 100000);
+	ret = rockchip_sfc_xfer_done(sfc, 100000);
+out:
+	pm_runtime_mark_last_busy(sfc->dev);
+	pm_runtime_put_autosuspend(sfc->dev);
+
+	return ret;
 }
 
 static int rockchip_sfc_adjust_op_size(struct spi_mem *mem, struct spi_mem_op *op)
@@ -581,18 +742,28 @@
 	if (IS_ERR(sfc->regbase))
 		return PTR_ERR(sfc->regbase);
 
-	sfc->clk = devm_clk_get(&pdev->dev, "clk_sfc");
+	if (!has_acpi_companion(&pdev->dev))
+		sfc->clk = devm_clk_get(&pdev->dev, "clk_sfc");
 	if (IS_ERR(sfc->clk)) {
 		dev_err(&pdev->dev, "Failed to get sfc interface clk\n");
 		return PTR_ERR(sfc->clk);
 	}
 
-	sfc->hclk = devm_clk_get(&pdev->dev, "hclk_sfc");
+	if (!has_acpi_companion(&pdev->dev))
+		sfc->hclk = devm_clk_get(&pdev->dev, "hclk_sfc");
 	if (IS_ERR(sfc->hclk)) {
 		dev_err(&pdev->dev, "Failed to get sfc ahb clk\n");
 		return PTR_ERR(sfc->hclk);
 	}
 
+	if (has_acpi_companion(&pdev->dev)) {
+		ret = device_property_read_u32(&pdev->dev, "clock-frequency", &sfc->frequency);
+		if (ret) {
+			dev_err(&pdev->dev, "Failed to find clock-frequency in ACPI\n");
+			return ret;
+		}
+	}
+
 	sfc->use_dma = !of_property_read_bool(sfc->dev->of_node,
 					      "rockchip,sfc-no-dma");
 
@@ -637,6 +808,17 @@
 		return ret;
 	}
 
+	platform_set_drvdata(pdev, sfc);
+
+	if (IS_ENABLED(CONFIG_ROCKCHIP_THUNDER_BOOT)) {
+		u32 status;
+
+		if (readl_poll_timeout(sfc->regbase + SFC_SR, status,
+				       !(status & SFC_SR_IS_BUSY), 10,
+				       500 * USEC_PER_MSEC))
+			dev_err(dev, "Wait for SFC idle timeout!\n");
+	}
+
 	ret = rockchip_sfc_init(sfc);
 	if (ret)
 		goto err_irq;
@@ -644,12 +826,25 @@
 	sfc->max_iosize = rockchip_sfc_get_max_iosize(sfc);
 	sfc->version = rockchip_sfc_get_version(sfc);
 
+	pm_runtime_set_autosuspend_delay(dev, ROCKCHIP_AUTOSUSPEND_DELAY);
+	pm_runtime_use_autosuspend(dev);
+	pm_runtime_set_active(dev);
+	pm_runtime_enable(dev);
+	pm_runtime_get_noresume(dev);
+
 	ret = spi_register_master(master);
 	if (ret)
-		goto err_irq;
+		goto err_register;
+
+	pm_runtime_mark_last_busy(dev);
+	pm_runtime_put_autosuspend(dev);
 
 	return 0;
 
+err_register:
+	pm_runtime_disable(sfc->dev);
+	pm_runtime_set_suspended(sfc->dev);
+	pm_runtime_dont_use_autosuspend(sfc->dev);
 err_irq:
 	clk_disable_unprepare(sfc->clk);
 err_clk:
@@ -671,6 +866,72 @@
 	return 0;
 }
 
+static int __maybe_unused rockchip_sfc_runtime_suspend(struct device *dev)
+{
+	struct rockchip_sfc *sfc = dev_get_drvdata(dev);
+
+	clk_disable_unprepare(sfc->clk);
+	clk_disable_unprepare(sfc->hclk);
+
+	return 0;
+}
+
+static int __maybe_unused rockchip_sfc_runtime_resume(struct device *dev)
+{
+	struct rockchip_sfc *sfc = dev_get_drvdata(dev);
+	int ret;
+
+	ret = clk_prepare_enable(sfc->hclk);
+	if (ret < 0)
+		return ret;
+
+	ret = clk_prepare_enable(sfc->clk);
+	if (ret < 0)
+		clk_disable_unprepare(sfc->hclk);
+
+	return ret;
+}
+
+static int __maybe_unused rockchip_sfc_suspend(struct device *dev)
+{
+	pinctrl_pm_select_sleep_state(dev);
+
+	return pm_runtime_force_suspend(dev);
+}
+
+static int __maybe_unused rockchip_sfc_resume(struct device *dev)
+{
+	struct rockchip_sfc *sfc = dev_get_drvdata(dev);
+	int ret;
+
+	ret = pm_runtime_force_resume(dev);
+	if (ret < 0)
+		return ret;
+
+	pinctrl_pm_select_default_state(dev);
+
+	ret = pm_runtime_get_sync(dev);
+	if (ret < 0) {
+		pm_runtime_put_noidle(dev);
+		return ret;
+	}
+
+	rockchip_sfc_init(sfc);
+	if (sfc->dll_cells)
+		rockchip_sfc_set_delay_lines(sfc, (u16)sfc->dll_cells);
+
+	pm_runtime_mark_last_busy(dev);
+	pm_runtime_put_autosuspend(dev);
+
+	return 0;
+}
+
+static const struct dev_pm_ops rockchip_sfc_pm_ops = {
+	SET_RUNTIME_PM_OPS(rockchip_sfc_runtime_suspend,
+			   rockchip_sfc_runtime_resume, NULL)
+	SET_SYSTEM_SLEEP_PM_OPS(rockchip_sfc_suspend, rockchip_sfc_resume)
+};
+
 static const struct of_device_id rockchip_sfc_dt_ids[] = {
 	{ .compatible = "rockchip,sfc"},
 	{ /* sentinel */ }
@@ -681,6 +942,7 @@
 	.driver = {
 		.name	= "rockchip-sfc",
 		.of_match_table = rockchip_sfc_dt_ids,
+		.pm = &rockchip_sfc_pm_ops,
 	},
 	.probe	= rockchip_sfc_probe,
 	.remove	= rockchip_sfc_remove,
